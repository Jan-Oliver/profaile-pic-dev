{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/huggingface/diffusers.git\n",
    "!cd /content/diffusers && pip install .\n",
    "!pip install transformers scipy ftfy accelerate\n",
    "!pip install \"ipywidgets>=7,<8\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on: https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb#scrollTo=AAVZStIokTVv\n",
    "\n",
    "Documentation:\n",
    "https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.8 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
    "\n",
    "# Checkout here which schedulers one can use out of the box:\n",
    "# https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion#diffusers.StableDiffusionPipeline\n",
    "scheduler = EulerDiscreteScheduler.from_pretrained(\"stabilityai/stable-diffusion-2-1-base\", subfolder=\"scheduler\")\n",
    "\n",
    "# revision and dtype make sure that we use lower GPU memory but maybe sacrifice some of the quality\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        \"stabilityai/stable-diffusion-2-1-base\",\n",
    "        scheduler=scheduler, \n",
    "        revision=\"fp16\", \n",
    "        torch_dtype=torch.float16,\n",
    "        requires_safety_checker=False\n",
    "    )  \n",
    "pipe = pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a photograph of an astronaut riding a black horse\"\n",
    "\n",
    "generator = torch.Generator(\"cuda\").manual_seed(1024)\n",
    "\n",
    "image = pipe(prompt, generator=generator).images[0]  # image here is in [PIL format](https://pillow.readthedocs.io/en/stable/)\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating multiple outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 3\n",
    "prompt = [\"a photograph of an astronaut riding a horse\"] * num_images\n",
    "\n",
    "generator = torch.Generator(\"cuda\").manual_seed(1024)\n",
    "\n",
    "images = pipe(prompt, generator=generator, num_inference_steps=15).images\n",
    "\n",
    "grid = image_grid(images, rows=1, cols=3)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator(\"cuda\").manual_seed(1024)\n",
    "\n",
    "images = pipe(prompt, generator=generator, num_inference_steps=5).images\n",
    "\n",
    "grid = image_grid(images, rows=1, cols=3)\n",
    "grid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
